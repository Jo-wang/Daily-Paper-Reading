## [Test time adaptation through perturbation robustness](https://arxiv.org/abs/2110.10232)

NeurIPS2021

### Introduction and background
- The motivation behind this paper is to address the problem of adapting to domain shift at inference time, without changing the training process. The authors note that data samples generated by several real-world processes are dynamic in nature, meaning their characteristics vary with time. Therefore, it is not possible to train and tackle all possible distributional shifts between training and inference using the host of transfer learning methods in literature.

- To address this problem, the authors propose a method called Test time Adaptation through Perturbation Robustness. This method quickly adapts the model at test-time to handle any domain shift by enforcing consistency of predictions of data sampled in the vicinity of test sample on the image manifold. The authors note that this method is simpler and lighter compared to its train-time adaptation counterparts.

- The proposed method has been tested on various scenarios like dealing with corruptions and domain adaptation, and has been shown to be effective at adapting to domain shift at inference time without changing the training process.

### Method
For each original test image, create two augmented one. And then do augmentation consistency.
<img width=700 alt="74e46c717cadcb63cb4ff0a0d1fb6d4" src="https://github.com/Jo-wang/Daily-Paper-Reading/assets/46414159/dc9dba43-b9c9-4fb4-a6f1-90daa1248088">

min the KL between each output with the mean of all of them. And then, min the ent during optimization for all of them:

<img width=700 alt="548e15390770068163a2dcbf80bbd5e" src="https://github.com/Jo-wang/Daily-Paper-Reading/assets/46414159/ac28817e-3a51-4fda-855e-62434e51cc26">

### Experiments
<img width=700 alt="be1c4cc52cd392b01c4c529c88dd14e" src="https://github.com/Jo-wang/Daily-Paper-Reading/assets/46414159/c6d9fcf0-59a3-43b7-af8f-0ba8d8f6ef84">

<img width=700 alt="88c77528014b29cae48ab2a06540b68" src="https://github.com/Jo-wang/Daily-Paper-Reading/assets/46414159/42599658-e87c-448b-992a-a39dba2b214d">

<img width=700 alt="61f57b29d22f8b2e6416ad446d5c2ac" src="https://github.com/Jo-wang/Daily-Paper-Reading/assets/46414159/f02e2043-08ee-4d76-b477-83bb3d77c697">


### Notes
- AugMix could get the best performance
