# Daily-Paper-Reading
Daily paper reading records

:question: -> plan to read

:star: -> good paper

:heavy_check_mark: -> finished for this week

:pushpin: -> group meeting talk this week

## Machine Learning
[Surrogate Gap Minimization Improves Sharpness-Aware Training](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/ml/Surrogate%20Gap%20Minimization%20Improves%20Sharpness-Aware%20Training.md)

:question: [Open-Set Recognition: A Good Closed-Set Classifier is All You Need](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/ml/Open-Set%20Recognition:%20A%20Good%20Closed-Set%20Classifier%20is%20All%20You%20Need.md)

[Image as Set of Points](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/ml/Image%20as%20Set%20of%20Points.md)

## Test-time Adaptation
[A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/A%20Comprehensive%20Survey%20on%20Test-Time%20Adaptation%20under%20Distribution%20Shifts.md)

❓ [Robust Test-Time Adaptation in Dynamic Scenarios](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Robust%20Test-Time%20Adaptation%20in%20Dynamic%20Scenarios.md)

❓ [TeSLA: Test-time self-learning with automatic adversarial augmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/TeSLA%3A%20Test-time%20self-learning%20with%20automatic%20adversarial%20augmentation.md)

❓ [DELTA: degradation-free fully test-time adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/DELTA%3A%20degradation-free%20fully%20test-time%20adaptation.md)

❓ [MECTA: Memory-Economic Continual Test-Time Model Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/MECTA%3A%20Memory-Economic%20Continual%20Test-Time%20Model%20Adaptation.md)

❓ [Parameter-free Online Test-time Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Parameter-free%20Online%20Test-time%20Adaptation.md)

❓ [Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Decorate%20the%20Newcomers%3A%20Visual%20Domain%20Prompt%20for%20Continual%20Test%20Time%20Adaptation.md)

❓ [Revisiting Realistic Test-Time Training: Sequential Inference and Adaptation by Anchored Clustering](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Revisiting%20realistic%20test-time%20training:%20Sequential%20inference%20and%20adaptation%20by%20anchored%20clustering.md)

❓ [MixNorm: Test-Time Adaptation Through Online Normalization Estimation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/MixNorm%3A%20Test-Time%20Adaptation%20Through%20Online%20Normalization%20Estimation.md)

❓ [Domain Alignment Meets Fully Test-Time Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Domain%20Alignment%20Meets%20Fully%20Test-Time%20Adaptation.md)

❓ [Test-time Adaptation via Conjugate Pseudo-Labels](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Test-time%20Adaptation%20via%20Conjugate%20Pseudo-Labels.md)

✔️ [Test-Time Adaptation to Distribution Shifts by Confidence Maximization and Input Transformation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Test-Time%20Adaptation%20to%20Distribution%20Shifts%20by%20Confidence%20Maximization%20and%20Input%20Transformation.md)

[Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Test-Time%20Classifier%20Adjustment%20Module%20for%20Model-Agnostic%20Domain%20Generalization.md)

[Test-time Batch Statistics Calibration for Covariate Shift](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Test-time%20Batch%20Statistics%20Calibration%20for%20Covariate%20Shift.md)

[Domain-agnostic Test-time Adaptation by Prototypical Training with Auxiliary Data](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Domain-agnostic%20test-time%20adaptation%20by%20prototypical%20training%20with%20auxiliary%20data.md)

[Test time Adaptation through Perturbation
Robustness](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Test%20time%20adaptation%20through%20perturbation%20robustness.md)

[Continual Test-Time Domain Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Continual%20Test-Time%20Domain%20Adaptation.md)

❓ [TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/TTT%2B%2B%3A%20When%20Does%20Self-Supervised%20Test-Time%20Training%20Fail%20or%20Thrive%3F.md)

[Improving Test-Time Adaptation via Shift-agnostic Weight Regularization and Nearest Source Prototypes](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Improving%20Test-Time%20Adaptation%20via%20Shift-agnostic%20Weight%20Regularization%20and%20Nearest%20Source%20Prototypes.md)

[Test-Time Training with Self-Supervision for Generalization under Distribution Shifts](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Test-Time%20Training%20with%20Self-Supervision%20for%20Generalization%20under%20Distribution%20Shifts.md)

[MEMO: Test Time Robustness via Adaptation and Augmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/MEMO:%20Test%20Time%20Robustness%20via%20Adaptation%20and%20Augmentation.md)

❓ [Extrapolative Continuous-time Bayesian Neural Network for Fast Training-free Test-time Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Extrapolative%20Continuous-time%20Bayesian%20Neural%20Network%20for%20Fast%20Training-free%20Test-time%20Adaptation.md)

[TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/TTN%3A%20A%20Domain-Shift%20Aware%20Batch%20Normalization%20in%20Test-Time%20Adaptation.md)

[The Norm Must Go On: Dynamic Unsupervised Domain Adaptation by Normalization](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/The%20Norm%20Must%20Go%20On%3A%20Dynamic%20Unsupervised%20Domain%20Adaptation%20by%20Normalization.md)

[Online Adaptation to Label Distribution Shift](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Online%20Adaptation%20to%20Label%20Distribution%20Shift.md)

[Improving robustness against common corruptions by covariate shift adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Improving%20robustness%20against%20common%20corruptions%20by%20covariate%20shift%20adaptation.md)

[MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/MM-TTA%3A%20Multi-Modal%20Test-Time%20Adaptation%20for%203D%20Semantic%20Segmentation.md)

[Efficient Test-Time Model Adaptation without Forgetting](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Efficient%20Test-Time%20Model%20Adaptation%20without%20Forgetting.md)

❓ [Back to the Source: Diffusion-Driven Test-Time Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Back%20to%20the%20Source:%20Diffusion-Driven%20Test-Time%20Adaptation.md)

[Test-Time Adaptation via Self-Training with Nearest Neighbor Information](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Test-Time%20Adaptation%20via%20Self-Training%20with%20Nearest%20Neighbor%20Information.md)

[NOTE: Robust Continual Test-time Adaptation Against Temporal Correlation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/NOTE%3A%20Robust%20Continual%20Test-time%20Adaptation%20Against%20Temporal%20Correlation.md)

[Towards Stable Test-time Adaptation in Dynamic Wild World](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Towards%20Stable%20Test-time%20Adaptation%20in%20Dynamic%20Wild%20World.md)

:pushpin: [Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/test-time/Neuro-Modulated%20Hebbian%20Learning%20for%20Fully%20Test-Time%20Adaptation.md)

:question: **medical** [Test-Time Unsupervised Domain Adaptation]()

## Imbalanced Data
[Learning to Re-weight Examples with Optimal Transport for Imbalanced Classification](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/imbalanced-data/Learning%20to%20Re-weight%20Examples%20with%20Optimal%20Transport%20for%20Imbalanced%20Classification.md)

:question: [ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/imbalanced-data/ACE:%20Ally%20Complementary%20Experts%20for%20Solving%20Long-Tailed%20Recognition%20in%20One-Shot.md)

:heavy_check_mark: [Posterior Re-calibration for Imbalanced Datasets](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/imbalanced-data/Posterior%20Re-calibration%20for%20Imbalanced%20Datasets.md)

## Transfer Learning things
:question: [Does Robustness on ImageNet Transfer to Downstream Tasks?]()

## Domain Adaptation (DA)
[Category Contrast for Unsupervised Domain Adaptation in Visual Tasks](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/Category%20Contrast%20for%20Unsupervised%20Domain%20Adaptation%20in%20Visual%20Tasks.md)

[Graph-Relational Domain Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/Graph-Relational%20Domain%20Adaptation.md)

[Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/Model%20Adaptation:%20Historical%20Contrastive%20Learning%20for%20Unsupervised%20Domain%20Adaptation%20without%20Source%20Data.md)

[Taskonomy: Disentangling Task Transfer Learning](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/Taskonomy:%20Disentangling%20Task%20Transfer%20Learning.md)

[Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/Source-Free%20Adaptation%20to%20Measurement%20Shift%20via%20Bottom-Up%20Feature%20Restoration.md)

[f-Domain-Adversarial Learning: Theory and Algorithms](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/f-Domain-Adversarial%20Learning:%20Theory%20and%20Algorithms.md)

:star: [Dirichlet-based Uncertainty Calibration for Active Domain Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/Dirichlet-based%20Uncertainty%20Calibration%20for%20Active%20Domain%20Adaptation.md)

:question: [Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/Addressing%20Parameter%20Choice%20Issues%20in%20Unsupervised%20Domain%20Adaptation%20by%20Aggregation.md)

### DA for Image Classification
[Cycle Self-Training for Domain Adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/image-classification/Cycle%20Self-Training%20for%20Domain%20Adaptation.md)

[Divide and Contrast: Source-free Domain Adaptation via Adaptive Contrastive Learning](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/image-classification/Divide%20and%20Contrast:%20Source-free%20Domain%20Adaptation%20via%20Adaptive%20Contrastive%20Learning.md)

[Toalign: Task-oriented alignment for unsupervised domain adaptation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/image-classification/Toalign:%20Task-oriented%20alignment%20for%20unsupervised%20domain%20adaptation.md)

[Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/image-classification/Model-Agnostic%20Meta-Learning%20for%20Fast%20Adaptation%20of%20Deep%20Networks.md)

:question: [Upcycling Models under Domain and Category Shift](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/image-classification/Upcycling%20Models%20under%20Domain%20and%20Category%20Shift.md)

[HyperDomainNet: Universal Domain Adaptation for Generative Adversarial Networks](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/image-classification/HyperDomainNet:%20Universal%20Domain%20Adaptation%20for%20Generative%20Adversarial%20Networks.md)

### DA for Semantic Segmentation
[Unsupervised Domain Adaptation for Semantic Segmentation using Depth Distribution](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/semantic-segmentation/Unsupervised%20Domain%20Adaptation%20for%20Semantic%20Segmentation%20using%20Depth%20Distribution.md)  

[Pixel-by-Pixel Cross-Domain Alignment for Few-Shot Semantic Segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/semantic-segmentation/Pixel-by-Pixel%20Cross-Domain%20Alignment%20for%20Few-Shot%20Semantic%20Segmentation.md)

[TACS: Taxonomy Adaptive Cross-Domain Semantic Segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-adaptation/semantic-segmentation/TACS:%20Taxonomy%20Adaptive%20Cross-Domain%20Semantic%20Segmentation.md)

:question: [Domain Transfer through Deep Activation Matching]()

### DA for online 3D segmentation
[GIPSO: Geometrically Informed Propagation for Online Adaptation in 3D LiDAR Segmentation]()

## 3D point cloud
[4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/3D-seg/4D%20Spatio-Temporal%20ConvNets:%20Minkowski%20Convolutional%20Neural%20Networks.md)

## Semantic Segmentation
### Transformer-based segmentation
[Segmenter: Transformer for Semantic Segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/transformer-seg/Segmenter:%20Transformer%20for%20Semantic%20Segmentation.md)

[Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/transformer-seg/Rethinking%20Semantic%20Segmentation%20from%20a%20Sequence-to-Sequence%20Perspective%20with%20Transformers.md)

[SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/transformer-seg/SegFormer:%20Simple%20and%20Efficient%20Design%20for%20Semantic%20Segmentation%20with%20Transformers.md)

### Segmentation model
❓ [Denoising Pretraining for Semantic Segmentation]()

❓ [Language-driven Semantic Segmentation]()

[Active Boundary Loss for Semantic Segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/segmentation/Active%20Boundary%20Loss%20for%20Semantic%20Segmentation.md)

[Segfix: Model-agnostic boundary refinement for segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/segmentation/Segfix:%20Model-agnostic%20boundary%20refinement%20for%20segmentation.md)

❓ [Segment Anything](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/segmentation/Segment%20Anything.md)

## Domain Generalization
[SWAD: Domain Generalization by Seeking Flat Minima](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/dg/SWAD:%20Domain%20Generalization%20by%20Seeking%20Flat%20Minima.md)

[Domain Generalization by Learning and Removing Domain-specific Features]()

[Ensemble of Averages: Improving Model Selection and Boosting Performance in Domain Generalization](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/domain-generalization/Ensemble%20of%20Averages:%20Improving%20Model%20Selection%20and%20Boosting%20Performance%20in%20Domain%20Generalization.md)

:question: [Sparse Mixture-of-Experts are Domain Generalizable Learners]()

## OOD 
[Assaying Out-Of-Distribution Generalization in Transfer Learning](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/OOD/Assaying%20Out-Of-Distribution%20Generalization%20in%20Transfer%20Learning.md)

[Visual Prompting via Image Inpainting](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/OOD/Visual%20Prompting%20via%20Image%20Inpainting.md)

[Uncertainty Modeling for Out-of-Distribution Generalization](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/OOD/Uncertainty%20Modeling%20for%20Out-of-Distribution%20Generalization.md)

[Delving Deep into the Generalization of Vision Transformers under Distribution Shifts](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/OOD/Delving%20Deep%20into%20the%20Generalization%20of%20Vision%20Transformers%20under%20Distribution%20Shifts.md)

[A Fine-Grained Analysis on Distribution Shift](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/OOD/A%20Fine-Grained%20Analysis%20on%20Distribution%20Shift.md)

:question: [Generalization to Out-of-Distribution transformations]()

:question: [Agree to Disagree: Diversity through Disagreement for Better Transferability](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/OOD/Agree%20to%20Disagree:%20Diversity%20through%20Disagreement%20for%20Better%20Transferability.md)

### OOD Detection
[Mitigating Neural Network Overconfidence with Logit Normalization](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/OOD/OOD-Detection/Mitigating%20Neural%20Network%20Overconfidence%20with%20Logit%20Normalization.md)

## PU Learning
[Positive-Unlabeled Learning with Non-Negative Risk Estimator]()

## semi-supervised SS
[Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation]()

## Continual Learning
[Learning To Prompt for Continual Learning](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/continual%20learning/Learning%20To%20Prompt%20for%20Continual%20Learning.md)

## Instance Segmentation

[SOLO: Segmenting Objects by Locations](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/instance-segmentation/SOLO:%20Segmenting%20Objects%20by%20Locations.md)

[SOLOv2: Dynamic and Fast Instance Segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/instance-segmentation/SOLOv2:%20Dynamic%20and%20Fast%20Instance%20Segmentation.md)

### Unsupervised instance segmentation
[Freesolo: Learning to segment objects without annotations](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/instance-segmentation/unsupervised-IS/Freesolo:%20Learning%20to%20segment%20objects%20without%20annotations.md)

[Dense Contrastive Learning for Self-Supervised Visual Pre-Training](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/instance-segmentation/unsupervised-IS/Dense%20Contrastive%20Learning%20for%20Self-Supervised%20Visual%20Pre-Training.md)

:question: [Cut and Learn for Unsupervised Object Detection and Instance Segmentation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/instance-segmentation/unsupervised-IS/Cut%20and%20Learn%20for%20Unsupervised%20Object%20Detection%20and%20Instance%20Segmentation.md)

## Transformer

:question: [Transformers are Sample-Efficient World Models](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/transformer/Transformers%20are%20Sample-Efficient%20World%20Models.md)

## Calibration
[Revisiting the Calibration of Modern Neural Networks](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/calibration/Revisiting%20the%20Calibration%20of%20Modern%20Neural%20Networks.md)

:question: [Mitigating Bias in Calibration Error Estimation](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/calibration/Mitigating%20Bias%20in%20Calibration%20Error%20Estimation.md)

## Model Selection

❓ [LogME: Practical Assessment of Pre-trained Models for Transfer Learning](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/model-selection/LogME:%20Practical%20Assessment%20of%20Pre-trained%20Models%20for%20Transfer%20Learning.md)

:pushpin: [Transferability Estimation Using Bhattacharyya Class Separability](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/model-selection/Transferability%20Estimation%20Using%20Bhattacharyya%20Class%20Separability.md)

:pushpin: [LEEP: A new measure to evaluate transferability of learned representations](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/model-selection/LEEP:%20A%20new%20measure%20to%20evaluate%20transferability%20of%20learned%20representations.md)

❓ [Scalable Diverse Model Selection for Accessible Transfer Learning]()

❓ [Transferability Metrics for Selecting Source Model Ensembles]()

❓ [Ranking and Tuning Pre-trained Models: A New Paradigm for Exploiting Model Hubs]()

## Dataset Distillation

[Dataset Distillation by Matching Training Trajectories](https://github.com/Jo-wang/Daily-Paper-Reading/blob/main/Dataset%20Distillation/Dataset%20Distillation%20by%20Matching%20Training%20Trajectories.md)

