## [SOLO: Segmenting Objects by Locations](https://arxiv.org/pdf/1912.04488.pdf)

ECCV2020

Ranking: :star: :star: :star: :star:

### Introduction and background
- it is challenging to predict instance labels on pixel-level
- Previous methods is "detect-then-segment" e.g., Mask R-CNN, PANet, Mask Scoring R-CNN, HTC; or, predict embedding vectors first then use clustering techniques to group pixels into individual instances, e.g., SGN, SSAP
- Previous methods are step-wise and indirect, which either heavily rely on accurate bounding box detection or depend on per-pixel embedding learning and the grouping processing
<img width="600" alt="1675047335019" src="https://user-images.githubusercontent.com/46414159/215377897-50f95f7a-8696-423d-a5c4-1b9de8d73889.png">

- SOLO can directly segment (e.g., AdaptIS, PolarMask) the instance masks.End-to-end.

### Method
<img width="700" alt="1675231816857" src="https://user-images.githubusercontent.com/46414159/215965301-0fc7669a-fae8-40f2-b42d-59a91727e754.png">

- Divide the image into uniform grids (S*S). If the center of an object falls into a grid cell, that grid cell is responsible for

  - predicting the semantic category (belongs to which class, output is SSC.
  - segmenting that object instance (the seg map, $H_I\times W_I\times S^2$)
  each positive grid cell will generate the corresponding instance mask
  (grid (i,j) is considered as a positive sample if it falls into the center region of any ground truth mask) This mask cannot be generated by FCNs since we need position sensitive in instance segmentation       
  this mask need coordconv method to get the coordinate of x, y
- non-maximum-suppression (NMS) is used to obtain the final instance segmentation results
- Overall Objective: $L = L_{\text{cate}} + \lambda L_{\text{mask}}$, where $L_{\text{cate}}$ is conventional Focal Loss. And, if a sample is positive, we need to compute the $L_{\text{mask}}$, which is a Dice Loss $d_{\text{mask}}$.        
  
  <img width="450" alt="1675232705946" src="https://user-images.githubusercontent.com/46414159/215967650-b37bc498-4ee6-4ed5-9243-118786c13903.png">          
    
  <img width="650" ait="1675232857766" src="https://user-images.githubusercontent.com/46414159/215968052-46200245-ad21-44bc-93e0-b076d50119e1.png">
    
- Inference:
  
  <img width="650" alt="1675233028409" src="https://user-images.githubusercontent.com/46414159/215968452-30ce461d-6bd3-4217-a31a-d6ec8dd163f6.png">
    
- Decoupled SOLO:
  
  <img width="450" alt="1675233154894" src="https://user-images.githubusercontent.com/46414159/215968827-1bf3c29f-4af4-4ff2-98e5-62d0ef4add51.png">
  
  <img width="600" alt="1675234052657" src="https://user-images.githubusercontent.com/46414159/215971497-f2bf9d5a-af44-4102-a182-a782d6b936a0.png">




  
### Experiments
- Dataset: MS COCO

<img width="700" alt="1675233343300" src="https://user-images.githubusercontent.com/46414159/215969289-ba34d837-3f07-4465-9f17-07625970e873.png">

### Ablation Study
<img width="600" alt="1675233695097" src="https://user-images.githubusercontent.com/46414159/215970380-4c4de53b-5be1-4e76-8073-4797be1b62ca.png">
<img width="600" alt="1675233744768" src="https://user-images.githubusercontent.com/46414159/215970514-4e5ecb50-b17f-4de0-b008-d4b6ac0ca80a.png">
<img width="600" alt="1675233784076" src="https://user-images.githubusercontent.com/46414159/215970647-3b0da9ef-7ec4-42e2-bbd7-c546a4d7dc8b.png">
<img width="600" alt="1675233823084" src="https://user-images.githubusercontent.com/46414159/215970787-aa99c6d3-0269-480d-b57f-41e3511c0bb2.png">
<img width="600" alt="1675233872173" src="https://user-images.githubusercontent.com/46414159/215970975-4692f9c8-ba6f-4b1f-9fc1-5672d16634c9.png">
<img width="600" alt="1675233939121" src="https://user-images.githubusercontent.com/46414159/215971142-3a55469a-aab7-498f-83fc-c55adef1a495.png">




### Notes
- CoordConv: https://zhuanlan.zhihu.com/p/39919038
- Non-Maximum Suppressionï¼ˆNMS): https://zhuanlan.zhihu.com/p/78504109
