## [Learning To Prompt for Continual Learning](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_To_Prompt_for_Continual_Learning_CVPR_2022_paper.html)
CVPR2022

Ranking: 4    
### Introduction and background
- model overfit on the currently available data, and
- suffers from performance deterioration on previous data due to catastrophic forgetting 
- Rehearsal buffer suffer from substantial performance deterioration with smaller buffer size, and
- ineffective when a rehearsal buffer is not allowed 
- Things need to be focused:
  - more intelligent and succinct episodic memory system?
  - automatically select relevant knowledge component for arbitrary sample **without knowing its task identity**?
- Solution: Proposes Learning to Prompt for Continual Learning (L2P)

### Method
![image](https://user-images.githubusercontent.com/46414159/208336162-a5e0720d-2532-4bbf-a73d-5a627562529a.png)

### Experiments

### Notes
