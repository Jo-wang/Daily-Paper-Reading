## [Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data](https://arxiv.org/abs/2110.03374)

NeurIPS2021

Ranking: ‚≠ê ‚≠ê ‚≠ê ‚≠ê

### Introduction and background
<img width="500" alt="Screen Shot 2023-01-08 at 23 43 20" src="https://user-images.githubusercontent.com/46414159/211199347-737b2284-e5aa-4273-9532-efbb76751930.png">

- This paper is mainly focusing on unsupervised model adaptation (another name of source-free DA ‚ùì) to adapt source-trained models to Ô¨Åt target data distribution without accessing the source-domain data.
- This setting alleviates the concern of data privacy and intellectual property effectively.
- More challenging and susceptible to collapse.
- Tested on image classification, semantic segmentation and object detection.

### Method
‚öñÔ∏è **Comparison between UDA and UMA**   
<img width="800" alt="Screen Shot 2023-01-08 at 23 47 21" src="https://user-images.githubusercontent.com/46414159/211199525-5f782ba5-fdf8-45f8-aef3-a277f365043b.png">

üîÑ **Model framework**   
<img width="800" alt="Screen Shot 2023-01-08 at 23 55 22" src="https://user-images.githubusercontent.com/46414159/211199993-197c0ae3-ebab-4fd6-a537-869efd80b09b.png">

#### Historical Contrastive Instance Discrimination (HCID)

#### Historical Contrastive Category Discrimination (HCCD)

### Experiments

### Notes
