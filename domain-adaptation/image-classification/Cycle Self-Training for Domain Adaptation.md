## [Cycle Self-Training for Domain Adaptation](https://arxiv.org/abs/2103.03571)
NeurIPS 2021

Ranking: 4.5
### Introduction and background
1. Self-training with pseudo labeling is a replacement of original feature alignment in domain adaptation.
2. Pseudo-labels are unreliable:
    -  pseudo-labels are biased towards several classes due to domain shift
    -  the denoising ability of pseudo-labels in standard self-training is hindered by domain shift

### Method
![Screen Shot 2022-11-07 at 16 19 10](https://user-images.githubusercontent.com/46414159/200239162-01979919-4579-47ac-a188-cfe5760eeba6.png)

Source distribution $P$, target distribution $Q$, model $f$ has feature extractor $h_{\phi}$ and a head (linear classifier) $g_{\theta}$.
#### Cycle Self-training
- Forward Step: source classifier $\theta _{s}$ trained on top of the shared representation $\phi$ , and then use it to generate target pesudo-labels:
![Screen Shot 2022-11-07 at 17 28 24](https://user-images.githubusercontent.com/46414159/200250768-5cac86f5-4671-463b-b00f-e4aa2f83b816.png)  
Drawbacks: 1. the output of deep networks is usually miscalibrated, and is not necessarily related to the ground-truth conﬁdence even on the same distribution; expensive tweaking in order to ﬁnd the optimal conﬁdence threshold.  
Expection: the model can gradually reﬁne the pseudo-labels by itself without the cumbersome selection or thresholding.
**(根据source model生成pseudo label)**

- Reverse Step: with the plabel $y'$ generated by source classifier $\theta _{s}$, we train a target head $\hat{\theta} _{t}(\phi)$ on top of $\phi$ with plabels on target domain $\hat{Q}$:<img width="220" alt="Screen Shot 2022-11-07 at 23 06 32" src="https://user-images.githubusercontent.com/46414159/200317778-71e46341-b357-4b9b-be7b-e8497d8e6d5c.png">
**(根据pseudo label学到新的分类器，但是特征提取器不变)**
Update the shared feature extractor $\phi$ to predict accurately on source and jointly enforce $\hat{\theta} _{t}(\phi)$ to perform well on source. **So that lead to Cycle Self-training**:<img width="320" alt="Screen Shot 2022-11-07 at 23 15 53" src="https://user-images.githubusercontent.com/46414159/200319723-3760bc67-78ef-407f-9c48-9cbf72355fdf.png">


- Bi-level Optimization

#### Tsallis Entropy Minimization

### Experiments

### Notes

